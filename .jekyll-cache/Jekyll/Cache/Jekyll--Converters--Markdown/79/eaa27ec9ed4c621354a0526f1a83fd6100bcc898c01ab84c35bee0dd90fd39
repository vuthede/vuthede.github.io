I"|<h3 id="1-introduce-eyegaze-model">1. Introduce eyegaze model</h3>
<ul>
  <li>Basically, eyegaze is the eye direction which can be used to indicate where the people are look at. e.g The red vectors in the image below are the eyegazes of people</li>
</ul>

<p><img src="images/360.png" alt="" /></p>

<ul>
  <li>Specifically in the Driver Monitor System, the eyegaze will help us to determine whether the driver‚Äôs eyes still focus on the road or not, if it‚Äôs not, then the system will make a distraction warning for the driver</li>
</ul>

<p><img src="images/gazevinaidms_distraction.png" alt="" /></p>

<ul>
  <li>Speaking of deep learning model design, the simplest  model will take the face of driver as the input ‚Äî&gt; backbone ‚Äî&gt; prediction</li>
</ul>

<p><img src="images/simple_gaze_arch.png" alt="" /></p>

<h3 id="2-why-need-uncertainty-estimation-in-production">2. WHY need uncertainty estimation in production?</h3>

<p>Let‚Äôs come back to Driver Monitor System.</p>

<p>In production, there are many cases that we‚Äôve not anticipated yet.</p>

<ul>
  <li>
    <p><strong>Case 1</strong>: The data might be very different from the train data. e.g The train data will be of Asian people with yellow skin, short hair but the real-world data will be of African, American with long hair and mustache and long eyelashes, etc</p>

    <p>At that time, <strong>the model might perform much worse, how do we detect those cases?</strong></p>

    <p>If we are able to detect it, we will collect data in those cases, label and add to the training dataset. It will help the model improve day by day. The more edges cases it detected, the more chance model will be improve. It is really cool, isn‚Äôt it?</p>
  </li>
  <li>
    <p><strong>Case 2</strong>: The camera is broken somehow make the quality image become too bad or the drivers‚Äôs eyes are occluded by eyeglasses, etc , infinite situations. In such situations, we want the model saying something like <strong>‚ÄúOhhh, there are something wrong with the input image, It looks so weird, I‚Äôve not ever seen something like that so I am not quite sure about my prediction. So I think you can not use my prediction to saying the driver is distraction‚Äù.</strong></p>

    <p><strong>How can the model do that?</strong> If there is, it is really cool, right?</p>
  </li>
</ul>

<p>Therefore, if the model can estimate the uncertainty of its predictions. It will help us improve the model performance (like Case 1) and  robustness of the system (like Case 2)</p>

<h3 id="3-how-to-estimate-uncertainty-of-model-prediction">3. HOW to estimate uncertainty of model prediction?</h3>
<ul>
  <li>
    <p>Firstly, in term of model design, we basically just add a new node which is the <strong>uncertainty node</strong></p>
  </li>
  <li>
    <p>Secondly, which is more important. How to train the uncertainty node? Do we need the label to supervise?‚Ä¶ Interestingly, the answer is No. We don‚Äôt need any more labels to supervise for the uncertainty node. The model can learn uncertainty itself if we add uncertainty to the right place in the loss function. Ok. so the magic is in the loss function. Let‚Äôs jump right to it: 
  Loss function:</p>
    <ul>
      <li>The vanilla loss function for regression problem as we know is MSE. In general cases, it usually work really well, that is why we usually using it. 
  <img src="images/l2.png" alt="" /></li>
      <li>
        <p>To handle the <strong>uncertainty</strong>, we basically just add the variance term as the denominator like</p>

        <p><img src="images/l2_vari.png" alt="" /></p>

        <p>How it make sense? How the model can optimize that loss so that the variance term is the uncertainty that we want. Intuitively, let‚Äôs consider 2 cases:</p>
        <ul>
          <li>
            <p>First case, when the input image to the model is easy (.i.e clear, high quality, no occlusion,  etc), then the <em>numerator term</em> tend to be small causing the overall loss is small.</p>
          </li>
          <li>
            <p>Second case, when the input image to the model is hard (.i.e blur, occlusion, etc), then the numerator term tend to be big, then in order to get the small overall loss, the <em>denominator</em> should be optimized to the larger number == high uncertainty. It is exactly what we want ‚Äú<em>When the model get hard images, it should return high uncertainty</em>‚Äù, right?</p>
          </li>
        </ul>

        <p>In conclusion, the vanilla MSE loss can only capture the mean value, which is the blue sine curve in the image below. In other hand, the proposed loss will capture both mean value and the uncertainty which is the blue shadow area in the image below. It help us know how confidence the model is about their prediction</p>

        <p><img src="images/example_uncertainty_data.png" alt="" /></p>

        <p><strong>If you want to dig deeper into that</strong>, I highly recommend you to read through references below.</p>
        <ul>
          <li><a href="https://livebook.manning.com/book/probabilistic-deep-learning-with-python/chapter-4/157">Probabilistic Deep Learning Book</a>. This book talks about deep learning in the probabilistic perspective. In chapter 4, it explain very clearly about how <em>uncertainty node</em> is optimized without any label for it.</li>
          <li><a href="https://arxiv.org/abs/1703.04977">What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?</a> <strong>.</strong>
  This paper give a good overall about different kind of uncertainty. In session 3, they also explain about the loss function used to estimate the uncertainty of the prediction.</li>
          <li><a href="https://arxiv.org/pdf/2105.09803.pdf">Weakly-Supervised Physically Unconstrained Gaze Estimation</a>. Session <em>Aleatoric Gaze Loss</em></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="4-demostration">4. Demostration</h3>
<p>I trained the model with the proposed loss function, and it worked as expected.
In the demostration video below, I try to act some scenarios that might happen in production. <strong>Please the image right below to see the video</strong></p>

<p><a href="images/confidence_eyegaze.webm"><img src="images/demo_low_variance.png" alt="Watch the video" /></a></p>

<ul>
  <li>When the eye are clear, then the gaze variance is small (around 0.05)
  <img src="images/demo_low_variance.png" alt="" /></li>
  <li>When the eye are occluded, then the gaze variance is bigger (around 0.25)
  <img src="images/demo_high_variance.png" alt="" /></li>
</ul>

<h3 id="5-how-to-convert-uncertainty-number-to-confidence-score-which-range-from-0-100">5. How to convert uncertainty number to confidence score which range from 0-100%</h3>
<p>The uncertainty returned from the model is numbers like 0.05, 0.10, 0.25, etc, which is not intuitive to understand.
So, it is neccessary to convert those uncertainty values to confidence value ranging from 0-100%.</p>

<p><strong>Coming soon‚Ä¶</strong></p>

:ET